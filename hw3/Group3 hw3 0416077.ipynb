{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification, Regression and Other Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We‘ll use \"201707-citibike-tripdata.csv.zip\" (after preprocessed in HW0)\n",
    "\n",
    "## Schema\n",
    "\n",
    "- Every station’s information\n",
    "    - id, name, lat, lng\n",
    "- Every stations’ flow data\n",
    "    - id, time, in-flow, out-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linsc04/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import os\n",
    "from time import time\n",
    "from plotly.graph_objs import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeClassifier\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv to dataframe\n",
    "use pandas to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364</td>\n",
       "      <td>2017-07-01 00:00:00</td>\n",
       "      <td>2017-07-01 00:06:05</td>\n",
       "      <td>539</td>\n",
       "      <td>Metropolitan Ave &amp; Bedford Ave</td>\n",
       "      <td>40.715348</td>\n",
       "      <td>-73.960241</td>\n",
       "      <td>3107</td>\n",
       "      <td>Bedford Ave &amp; Nassau Ave</td>\n",
       "      <td>40.723117</td>\n",
       "      <td>-73.952123</td>\n",
       "      <td>14744</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2142</td>\n",
       "      <td>2017-07-01 00:00:03</td>\n",
       "      <td>2017-07-01 00:35:46</td>\n",
       "      <td>293</td>\n",
       "      <td>Lafayette St &amp; E 8 St</td>\n",
       "      <td>40.730207</td>\n",
       "      <td>-73.991026</td>\n",
       "      <td>3425</td>\n",
       "      <td>2 Ave  &amp; E 104 St</td>\n",
       "      <td>40.789210</td>\n",
       "      <td>-73.943708</td>\n",
       "      <td>19587</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>2017-07-01 00:00:08</td>\n",
       "      <td>2017-07-01 00:05:37</td>\n",
       "      <td>3242</td>\n",
       "      <td>Schermerhorn St &amp; Court St</td>\n",
       "      <td>40.691029</td>\n",
       "      <td>-73.991834</td>\n",
       "      <td>3397</td>\n",
       "      <td>Court St &amp; Nelson St</td>\n",
       "      <td>40.676395</td>\n",
       "      <td>-73.998699</td>\n",
       "      <td>27937</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2530</td>\n",
       "      <td>2017-07-01 00:00:11</td>\n",
       "      <td>2017-07-01 00:42:22</td>\n",
       "      <td>2002</td>\n",
       "      <td>Wythe Ave &amp; Metropolitan Ave</td>\n",
       "      <td>40.716887</td>\n",
       "      <td>-73.963198</td>\n",
       "      <td>398</td>\n",
       "      <td>Atlantic Ave &amp; Furman St</td>\n",
       "      <td>40.691652</td>\n",
       "      <td>-73.999979</td>\n",
       "      <td>26066</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2534</td>\n",
       "      <td>2017-07-01 00:00:15</td>\n",
       "      <td>2017-07-01 00:42:29</td>\n",
       "      <td>2002</td>\n",
       "      <td>Wythe Ave &amp; Metropolitan Ave</td>\n",
       "      <td>40.716887</td>\n",
       "      <td>-73.963198</td>\n",
       "      <td>398</td>\n",
       "      <td>Atlantic Ave &amp; Furman St</td>\n",
       "      <td>40.691652</td>\n",
       "      <td>-73.999979</td>\n",
       "      <td>29408</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration            starttime             stoptime  start station id  \\\n",
       "0           364  2017-07-01 00:00:00  2017-07-01 00:06:05               539   \n",
       "1          2142  2017-07-01 00:00:03  2017-07-01 00:35:46               293   \n",
       "2           328  2017-07-01 00:00:08  2017-07-01 00:05:37              3242   \n",
       "3          2530  2017-07-01 00:00:11  2017-07-01 00:42:22              2002   \n",
       "4          2534  2017-07-01 00:00:15  2017-07-01 00:42:29              2002   \n",
       "\n",
       "               start station name  start station latitude  \\\n",
       "0  Metropolitan Ave & Bedford Ave               40.715348   \n",
       "1           Lafayette St & E 8 St               40.730207   \n",
       "2      Schermerhorn St & Court St               40.691029   \n",
       "3    Wythe Ave & Metropolitan Ave               40.716887   \n",
       "4    Wythe Ave & Metropolitan Ave               40.716887   \n",
       "\n",
       "   start station longitude  end station id          end station name  \\\n",
       "0               -73.960241            3107  Bedford Ave & Nassau Ave   \n",
       "1               -73.991026            3425         2 Ave  & E 104 St   \n",
       "2               -73.991834            3397      Court St & Nelson St   \n",
       "3               -73.963198             398  Atlantic Ave & Furman St   \n",
       "4               -73.963198             398  Atlantic Ave & Furman St   \n",
       "\n",
       "   end station latitude  end station longitude  bikeid    usertype  \\\n",
       "0             40.723117             -73.952123   14744  Subscriber   \n",
       "1             40.789210             -73.943708   19587  Subscriber   \n",
       "2             40.676395             -73.998699   27937  Subscriber   \n",
       "3             40.691652             -73.999979   26066  Subscriber   \n",
       "4             40.691652             -73.999979   29408  Subscriber   \n",
       "\n",
       "   birth year  gender  \n",
       "0      1986.0       1  \n",
       "1      1981.0       1  \n",
       "2      1984.0       2  \n",
       "3      1985.0       1  \n",
       "4      1982.0       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessed dataset\n",
    "df = pd.read_csv('./201707-citibike-tripdata-preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station id</th>\n",
       "      <th>station name</th>\n",
       "      <th>station latitude</th>\n",
       "      <th>station logitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>539</td>\n",
       "      <td>Metropolitan Ave &amp; Bedford Ave</td>\n",
       "      <td>40.715348</td>\n",
       "      <td>-73.960241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>Lafayette St &amp; E 8 St</td>\n",
       "      <td>40.730207</td>\n",
       "      <td>-73.991026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3242</td>\n",
       "      <td>Schermerhorn St &amp; Court St</td>\n",
       "      <td>40.691029</td>\n",
       "      <td>-73.991834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>Wythe Ave &amp; Metropolitan Ave</td>\n",
       "      <td>40.716887</td>\n",
       "      <td>-73.963198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361</td>\n",
       "      <td>Allen St &amp; Hester St</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-73.991908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station id                    station name  station latitude  \\\n",
       "0         539  Metropolitan Ave & Bedford Ave         40.715348   \n",
       "1         293           Lafayette St & E 8 St         40.730207   \n",
       "2        3242      Schermerhorn St & Court St         40.691029   \n",
       "3        2002    Wythe Ave & Metropolitan Ave         40.716887   \n",
       "4         361            Allen St & Hester St         40.716059   \n",
       "\n",
       "   station logitude  \n",
       "0        -73.960241  \n",
       "1        -73.991026  \n",
       "2        -73.991834  \n",
       "3        -73.963198  \n",
       "4        -73.991908  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every station's information\n",
    "station_info = pd.read_csv('./station_info.csv')\n",
    "station_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>79</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>116</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>143</th>\n",
       "      <th>...</th>\n",
       "      <th>2003</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    72   79   82   83  116  119  120  127  128  143  ...   2003  2005  2006  \\\n",
       "0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  1.0  0.0  ...    1.0   0.0   0.0   \n",
       "2  2.0  0.0  0.0  0.0  0.0  0.0  1.0  2.0  1.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  0.0  1.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  ...    2.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  2.0  1.0  ...    1.0   0.0   1.0   \n",
       "\n",
       "   2008  2009  2010  2012  2021  2022  2023  \n",
       "0   3.0   1.0   0.0   1.0   0.0   0.0   0.0  \n",
       "1   2.0   0.0   1.0   0.0   2.0   0.0   1.0  \n",
       "2   1.0   0.0   1.0   1.0   0.0   0.0   0.0  \n",
       "3   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every station's in-flow data\n",
    "station_in_flow = pd.read_csv('./in_flow.csv')\n",
    "station_in_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>79</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>116</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>143</th>\n",
       "      <th>...</th>\n",
       "      <th>2003</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    72   79   82   83  116  119  120  127  128  143  ...   2003  2005  2006  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  3.0  0.0  ...    0.0   0.0   1.0   \n",
       "1  0.0  0.0  0.0  1.0  1.0  0.0  1.0  1.0  4.0  0.0  ...    0.0   0.0   0.0   \n",
       "2  1.0  1.0  0.0  2.0  0.0  0.0  2.0  0.0  2.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    2.0   0.0   0.0   \n",
       "4  0.0  2.0  0.0  0.0  1.0  0.0  2.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "\n",
       "   2008  2009  2010  2012  2021  2022  2023  \n",
       "0   3.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "2   2.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "3   0.0   0.0   1.0   0.0   1.0   0.0   1.0  \n",
       "4   0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every station's out-flow data\n",
    "station_out_flow = pd.read_csv('./out_flow.csv')\n",
    "station_out_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using historical (14 days) data to predict every station's outflow tomorrow (1 day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract following values\n",
    "\n",
    "- station_id\n",
    "- outflow(and this is we want to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>79</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>116</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>143</th>\n",
       "      <th>...</th>\n",
       "      <th>2003</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    72   79   82   83  116  119  120  127  128  143  ...   2003  2005  2006  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  3.0  0.0  ...    0.0   0.0   1.0   \n",
       "1  0.0  0.0  0.0  1.0  1.0  0.0  1.0  1.0  4.0  0.0  ...    0.0   0.0   0.0   \n",
       "2  1.0  1.0  0.0  2.0  0.0  0.0  2.0  0.0  2.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    2.0   0.0   0.0   \n",
       "4  0.0  2.0  0.0  0.0  1.0  0.0  2.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "\n",
       "   2008  2009  2010  2012  2021  2022  2023  \n",
       "0   3.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "2   2.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "3   0.0   0.0   1.0   0.0   1.0   0.0   1.0  \n",
       "4   0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_out_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize outflow\n",
    "- discretize with divided by every station's outflow standard deviation and round to integer\n",
    "- process them so it can be solve as a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By previous homework's results, we can find divided by 5 is a good way to discretize so apply it and round the value to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>79</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>116</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>143</th>\n",
       "      <th>...</th>\n",
       "      <th>2003</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    72   79   82   83  116  119  120  127  128  143  ...   2003  2005  2006  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   0.0   \n",
       "\n",
       "   2008  2009  2010  2012  2021  2022  2023  \n",
       "0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_out_dis = (station_out_flow / 5).round(0)\n",
    "station_out_dis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use previous (14 days) data to estimate next days’ outflow\n",
    "- use a sliding window to increase our data (shift k days each time, and determine the k = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(isdis, idx, st):\n",
    "    if isdis == True:\n",
    "        df = pd.DataFrame(station_out_dis.iloc[st * 48 : (15 + st) * 48, idx]).T\n",
    "    else:\n",
    "        df = pd.DataFrame(station_out_flow.iloc[st * 48 : (15 + st) * 48, idx]).T\n",
    "    df.columns = [i for i in range(df.shape[1])]\n",
    "    return df\n",
    "\n",
    "def get_station(isdis, idx):\n",
    "    data = pd.DataFrame()\n",
    "    res = []\n",
    "    for i in range(16):\n",
    "        data = data.append(get_data(isdis, idx, i))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use ```get_station(is_discrete, index)``` to get the station's outflow data from 7/01 - 7/15 to 7/16 - 7/30 in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   710  711  712  713  \\\n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  1.0  0.0  1.0   \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  1.0   \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  1.0  1.0  1.0   \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   2.0  1.0  0.0  0.0   \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  1.0  1.0  1.0   \n",
       "\n",
       "    714  715  716  717  718  719  \n",
       "79  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "79  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "79  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "79  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 720 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_station(True, 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate each model\n",
    "\n",
    "Calculate the mean accuracy, mean square error and using time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_model(isdis, clf):\n",
    "    ans = 0\n",
    "    t = time()\n",
    "    for idx in range(634):\n",
    "        data = get_station(isdis, idx)\n",
    "        train_x, test_x, train_y, test_y = train_test_split(data.iloc[:, :14 * 48], data.iloc[:, 14 * 48:], test_size = 0.3)\n",
    "        for i in range(48):\n",
    "            ans += clf.fit(train_x, train_y.iloc[:, i]).score(test_x, test_y.iloc[:, i])\n",
    "    if isdis == True:\n",
    "        print 'Average accuracy for 48 timeslot: {:.4f}'.format((ans / 634.0 / 48.0))\n",
    "    else:\n",
    "        print 'Mean square error for 48 timeslot: {:.4f}'.format((ans / 634.0 / 48.0))\n",
    "    print 'Time: {:.2f} sec'.format(time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try following models (as classification problem)\n",
    "\n",
    "compare the computation time and result ( average accuracy for 48 timeslot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbor\n",
    "\n",
    "Classifier implementing the k-nearest neighbors vote.\n",
    "\n",
    "By previous homework, the results of Kmeans and PCA => Agglomerative Clustering look like we can divided the data into 3 - 4 parts so we choose k = 3 or 4.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7744\n",
      "Time: 113.93 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors = 3))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7927\n",
      "Time: 111.33 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors = 4))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Try multinomial and Gaussian to predict the data.\n",
    "\n",
    "- Naive Bayes classifier for multinomial models\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "\n",
    "Can perform online updates to model parameters via partial_fit method. For details on algorithm used to update feature means and variance online, see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
    "http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7914\n",
      "Time: 100.05 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7692\n",
      "Time: 104.89 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(GaussianNB())\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "That is a random forest classifier and setting max_depth to prevent the decision tree being too deep leads to overfitting and wasting time.\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7858\n",
      "Time: 812.33 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(max_depth = 2))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7853\n",
      "Time: 791.89 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(max_depth = 5))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine(SVC)\n",
    "\n",
    "C-Support Vector Classification and the implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\n",
    "\n",
    "Try to use different kernels to see the accuracy and using time.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear\n",
      "Average accuracy for 48 timeslot: 0.7938\n",
      "Time: 106.20 sec\n",
      "kernel: poly\n",
      "Average accuracy for 48 timeslot: 0.7913\n",
      "Time: 104.60 sec\n",
      "kernel: rbf\n",
      "Average accuracy for 48 timeslot: 0.7944\n",
      "Time: 109.78 sec\n",
      "kernel: sigmoid\n",
      "Average accuracy for 48 timeslot: 0.7915\n",
      "Time: 109.39 sec\n"
     ]
    }
   ],
   "source": [
    "ker = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for item in ker:\n",
    "    print 'kernel: {}'.format(item)\n",
    "    clf = OneVsRestClassifier(SVC(kernel = item))\n",
    "    eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other\n",
    "\n",
    "Use extremely randomized tree classifier to predict the data.\n",
    "\n",
    "Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.\n",
    "\n",
    "Also setting max_depth to prevent the decision tree being too deep leads to overfitting and wasting time.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7402\n",
      "Time: 95.40 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(ExtraTreeClassifier(max_depth = 2))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7291\n",
      "Time: 96.90 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(ExtraTreeClassifier(max_depth = 5))\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-Nearest-Neighbor\n",
    "\n",
    "n_neighbors is set to 4 is more accuracy but the time it takes is also more. They take about 105 seconds and the accuracy is almost 80%.\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "Choose the multinomial naive bayes is better because the outflows are match the multinomial model rather than Gaussian during weekday and weekend. The time they take is less than KNN and Multinomial's accuracy is almost 80% too.\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "Compared with the max_depth and I find the time is getting much without improving accuracy. The time is much more than other models because it builds many trees to decide the predicted results.\n",
    "\n",
    "- Support vector machine(SVC)\n",
    "\n",
    "Every kernel's results are almost the same but sometime we can find accuracy is a little bit higher and taking less time in linear kernel.\n",
    "\n",
    "- Extremely Randomized Tree\n",
    "\n",
    "Extremely randomized tree classifier's accuracy is less than other models and the using time is not decreasing. QQ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the label by collecting all the target values and construct the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = set()\n",
    "\n",
    "for i in range(48):\n",
    "    for item in pd.unique(station_out_dis.iloc[:, -i]):\n",
    "        label.add(item)\n",
    "label = list(label)\n",
    "num_l = len(label)\n",
    "\n",
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "mat = np.zeros([num_l, num_l], dtype = np.int)\n",
    "for idx in range(634):\n",
    "        data = get_station(True, idx)\n",
    "        train_x, test_x, train_y, test_y = train_test_split(data.iloc[:, :14 * 48], data.iloc[:, 14 * 48:], test_size = 0.3)\n",
    "        mat += (confusion_matrix(clf.fit(train_x, train_y.iloc[:, 0]).predict(test_x), test_y.iloc[:, 0], labels = label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the confusion matrix for predicting the first hour in one day\n",
    "for Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2977,  156,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  24,   10,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance with different parameters in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test following parameters\n",
    "\n",
    "- kernel\n",
    "    - linear\n",
    "    - poly\n",
    "    - rbf\n",
    "    - sigmoid\n",
    "\n",
    "They are almost the same performance in using time about 130 seconds and the random training data causing the results a little different.\n",
    "\n",
    "The linear and poly kernel are different from the power of distribution and the predicted results are higher than tbf sometimes because the testing data matches the distribution sometime.\n",
    "\n",
    "We can find the accuracy in rbf kernel sometimes higher than the others and I think the reason is rbf can approximate of any non-linear function in  high precision. So it could be more match than the others and from previos work we know the data is more close to mutinormal distribution.\n",
    "\n",
    "Sigmoid model is similar to the logistic regression model and the using time is more than others because it defines curves according to where the logistic value is greater than some value (modeling probability).\n",
    "\n",
    "According to above models, I consider the best model is rbf because it can match the training data in whatever linear, polynomial or something high dimensional distribution and takes not much time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try following models (as regression problem)\n",
    "\n",
    "compare the computation time and result ( Mean square error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ARIMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:              D.outflow   No. Observations:                 1487\n",
      "Model:                 ARIMA(1, 1, 1)   Log Likelihood               -3537.951\n",
      "Method:                       css-mle   S.D. of innovations              2.612\n",
      "Date:                Fri, 29 Dec 2017   AIC                           7083.902\n",
      "Time:                        13:25:40   BIC                           7105.120\n",
      "Sample:                    07-01-2017   HQIC                          7091.810\n",
      "                         - 07-31-2017                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const               0.0010      0.031      0.031      0.975      -0.060       0.061\n",
      "ar.L1.D.outflow     0.0221      0.059      0.374      0.708      -0.094       0.138\n",
      "ma.L1.D.outflow    -0.5549      0.052    -10.589      0.000      -0.658      -0.452\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                 Real           Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1           45.3223           +0.0000j           45.3223            0.0000\n",
      "MA.1            1.8020           +0.0000j            1.8020            0.0000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rng = list(pd.date_range(\"2017-07-01 00:00:00\", \"2017-07-31 23:30:00\", freq = \"30min\"))\n",
    "ts = pd.DataFrame(station_out_flow.iloc[:, 0].values, index = rng)\n",
    "\n",
    "ts.columns = ['outflow']\n",
    "mod = ARIMA(ts, order = (1,1,1))\n",
    "\n",
    "res = mod.fit(disp = False)\n",
    "print res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian regression\n",
    "\n",
    "Use Bayesian ridge regression and try to set n_iter to see how much time it takes and how accuracy it inprove.\n",
    "\n",
    "Fit a Bayesian ridge model and optimize the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.4735\n",
      "Time: 439.15 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(BayesianRidge(n_iter = 300))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.4758\n",
      "Time: 453.75 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(BayesianRidge(n_iter = 500))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regression\n",
    "\n",
    "A decision tree but use a regressor. Also setting max_depth to prevent the decision tree being too deep leads to overfitting and wasting time. And see how much time it takes and how accuracy it inprove.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.3789\n",
      "Time: 206.85 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(DecisionTreeRegressor(max_depth = 2))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.3765\n",
      "Time: 205.92 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(DecisionTreeRegressor(max_depth = 5))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine(SVR)\n",
    "\n",
    "Use Epsilon-Support Vector Regression and the implementation is based on libsvm.\n",
    "\n",
    "Also try some kernel to see the results and time it takes.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear\n",
      "Mean square error for 48 timeslot: 0.4746\n",
      "Time: 193.11 sec\n",
      "kernel: poly\n",
      "Mean square error for 48 timeslot: 0.4774\n",
      "Time: 204.27 sec\n",
      "kernel: rbf\n",
      "Mean square error for 48 timeslot: 0.4807\n",
      "Time: 209.20 sec\n",
      "kernel: sigmoid\n",
      "Mean square error for 48 timeslot: 0.4633\n",
      "Time: 192.35 sec\n"
     ]
    }
   ],
   "source": [
    "ker = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for item in ker:\n",
    "    print 'kernel: {}'.format(item)\n",
    "    clf = OneVsRestClassifier(SVR(kernel = item))\n",
    "    eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other\n",
    "\n",
    "\n",
    "Regression based on k-nearest neighbors.\n",
    "\n",
    "The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.4308\n",
      "Time: 207.16 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(KNeighborsRegressor(n_neighbors = 3))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.4502\n",
      "Time: 208.90 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(KNeighborsRegressor(n_neighbors = 4))\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ARIMA\n",
    "\n",
    "Autoregressive Integrated Moving Average ARIMA(p,d,q) Model and the order is (p,d,q) order of the model for the number of AR parameters, differences, and MA parameters to use. And the model's error rate is less than others sometimes.\n",
    "\n",
    "- Bayesian regression\n",
    "\n",
    "Using Bayesian ridge regression, fitting a Bayesian ridge model and optimizing the regularization parameters lambda (precision of the weights) and alpha (precision of the noise). So the using time is much more.\n",
    "\n",
    "- Decision tree regression\n",
    "\n",
    "The strategy used to choose the split at each node, supported strategies are “best” to choose the best split. And criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node. So the mean square error is low.\n",
    "\n",
    "- Support vector machine(SVR)\n",
    "\n",
    "Compared to SVC, the results are more less error rate. And also taking more time, to other regression models are more high error rate.\n",
    "\n",
    "- Regression k-nearest neighbors\n",
    "\n",
    "The regression knn weighted every node and than do knn, so the using time is more than SVR, decision tree. More fitable than knn but using time is more much too.\n",
    "\n",
    "The using time of regression models is more than classification models but the results seens more accuracy and low error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try other method to solve this prediction problem,and give a result and some explanation.\n",
    "\n",
    "Using linear SVC and linear SVR.\n",
    "\n",
    "Linear Support Vector Classification.\n",
    "\n",
    "Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "\n",
    "Linear Support Vector Regression.\n",
    "\n",
    "Similar to SVR with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "This class supports both dense and sparse input.\n",
    "\n",
    "[package](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 48 timeslot: 0.7940\n",
      "Time: 97.47 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "eval_model(True, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for 48 timeslot: 0.4750\n",
      "Time: 226.71 sec\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVR())\n",
    "eval_model(False, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC model's accuracy is less than others sometime but the using time is less. Could cause it implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "The outcomes of the Linear SVR are much the same of the SVR model in linear kernel but the mean square error is less than the just SVR model. I think it could be good at the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "And we can find that in large dataset, using linear SVC or SVR would predict much accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
